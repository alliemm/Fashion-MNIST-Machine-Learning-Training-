import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import sklearn.metrics 

iters = 30
learning_rate = .0012
reg_rate = .0002
experimentAccResults = []
experimentRegRate = []
experimentLossResults = []
experimentLearningRate = []
# fashion_mnist = tf.keras.datasets.fashion_mnist


# (train_images, train_labels), (test_images, test_labels) = 



(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()

# Normalize pixel values to be between 0 and 1
train_images, test_images = train_images / 255.0, test_images / 255.0
# train_images = train_images / 255.0

# test_images = test_images / 255.0

train_images=train_images.reshape(train_images.shape+(1,))
# test_images=test_images.reshape(test_images.shape+(1,))
# train_images = np.array(train_images)
# test_images = np.array(train_images)
print(train_images.shape)
# print(train_images[3][1].shape)


# model= tf.keras.models.Sequential([
#     # layer 1
#     # tf.keras.Input(shape=(train_images.shape[1],train_images.shape[2],train_images.shape[3])),
#     tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(224, 224, 3), use_bias=True),
#     tf.keras.layers.MaxPooling2D(2,2),
#     # layer 2
#     tf.keras.layers.Conv2D(64, (3,3), activation = 'relu', use_bias=True),
#     tf.keras.layers.MaxPooling2D(2,2),
#     # layer 3
#     tf.keras.layers.Conv2D(128, (3,3), activation = 'relu', use_bias=True, kernel_regularizer =tf.keras.regularizers.l2(0.01)),
#     tf.keras.layers.MaxPooling2D(2,2),
#     # layer 4
#     tf.keras.layers.Conv2D(128, (3,3), activation = 'relu', use_bias=True , kernel_regularizer =tf.keras.regularizers.l2(0.01)),
#     tf.keras.layers.MaxPooling2D(2,2),
#     tf.keras.layers.Flatten(),
#     # layer 5
#     tf.keras.layers.Dense(512, activation = 'relu', use_bias=True,  kernel_regularizer =tf.keras.regularizers.l2(0.01)),
    
#     # layer 6
#     tf.keras.layers.Dense(3, activation='softmax', use_bias=True)
    
# ])
# for i in range(5,10):
#     learning_rate = i*.0002

#     print("learning rate : ",learning_rate)
#     model.compile(tf.keras.optimizers.Adam(learning_rate=learning_rate),
#                 loss=tf.keras.losses.SparseCategoricalCrossentropy(),
#                 metrics=['accuracy'])



#     history = model.fit(train_images, train_labels, epochs=iters)

#     acc_matrix = history.history['accuracy']
#     loss_matrix = history.history['loss']

#     test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)
#     experimentLearningRate.append(learning_rate)
#     experimentAccResults.append(test_acc)
#     experimentLossResults.append(test_loss)

# for i in range(1,10):
#     reg_rate = i*.0001
#     print("reg rate : ",reg_rate)
    
#     model = tf.keras.models.Sequential()
#     model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(train_images.shape[1:4])))
#     model.add(tf.keras.layers.MaxPooling2D((2, 2)))
#     model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer =tf.keras.regularizers.l2(reg_rate)))
#     model.add(tf.keras.layers.MaxPooling2D((2, 2)))
#     model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer =tf.keras.regularizers.l2(reg_rate)))
#     model.add(tf.keras.layers.MaxPooling2D((2, 2)))
#     model.add(tf.keras.layers.Flatten())
#     model.add(tf.keras.layers.Dense(512, activation='relu', kernel_regularizer =tf.keras.regularizers.l2(reg_rate)))
#     model.add(tf.keras.layers.Dense(10, activation='softmax'))

#     model.compile(tf.keras.optimizers.Adam(learning_rate=learning_rate),
#                 loss=tf.keras.losses.SparseCategoricalCrossentropy(),
#                 metrics=['accuracy'])



#     history = model.fit(train_images, train_labels, epochs=iters)

#     acc_matrix = history.history['accuracy']
#     loss_matrix = history.history['loss']

#     test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)
#     experimentRegRate.append(reg_rate)
#     experimentAccResults.append(test_acc)
#     experimentLossResults.append(test_loss)


model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='sigmoid', input_shape=(train_images.shape[1:4])))
model.add(tf.keras.layers.MaxPooling2D((2, 2)))
model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='sigmoid', kernel_regularizer =tf.keras.regularizers.l2(reg_rate)))
model.add(tf.keras.layers.MaxPooling2D((2, 2)))
model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='sigmoid', kernel_regularizer =tf.keras.regularizers.l2(reg_rate)))
model.add(tf.keras.layers.MaxPooling2D((2, 2)))
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(512, activation='sigmoid', kernel_regularizer =tf.keras.regularizers.l2(reg_rate)))
model.add(tf.keras.layers.Dense(10, activation='softmax'))

model.compile(tf.keras.optimizers.Adam(learning_rate=learning_rate),
            loss=tf.keras.losses.SparseCategoricalCrossentropy(),
            metrics=['accuracy'])


history = model.fit(train_images, train_labels, epochs=iters)

test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)
acc_matrix = history.history['accuracy']
loss_matrix = history.history['loss']
predictions = model.predict(test_images)
predictions = np.argmax(predictions, axis=1)
print(predictions)
print("precision: ", sklearn.metrics.precision_score(test_labels,predictions,average='macro'))
print("recall: ",sklearn.metrics.recall_score(test_labels,predictions,average='macro'))

# print('\nTest accuracy:', test_acc)
# np.savetxt('CNN results reg rate.csv',(experimentRegRate,experimentAccResults,experimentLossResults), delimiter=',')
# plt.plot(experimentRegRate,experimentAccResults)
# plt.savefig('accuracy across reg rate CNN.png',dpi=300,bbox_inches='tight')
# plt.show()
epochs = np.arange(1,iters+1,1)
print(epochs)
print(acc_matrix)
plt.plot(epochs, acc_matrix)
plt.xlabel("X - Iterations")
plt.ylabel("Y - Training Accuracy")
plt.ylim(min(acc_matrix),max(acc_matrix))
plt.title('CNN accuracy iters '+ str(iters)  + ' learning_rate '+ str(learning_rate)  + ' reg ' + str(reg_rate)+ ' test accuracy = '+str(test_acc))
plt.savefig('CNN accuracy iters '+ str(iters)  + ' learning_rate '+ str(learning_rate)  + ' reg ' + str(reg_rate) + '.png', dpi=300, bbox_inches='tight')
plt.show()
plt.plot(epochs, loss_matrix)
plt.xlabel("X - Iterations")
plt.ylabel("Y - Training Loss")
plt.ylim(0,max(loss_matrix))
plt.title('CNN loss iters '+ str(iters)  + ' learning_rate '+ str(learning_rate)  + ' reg ' + str(reg_rate)+ ' test loss = '+str(test_loss))
plt.savefig('CNN loss iters '+ str(iters)  + ' learning_rate '+ str(learning_rate)  + ' reg ' + str(reg_rate) + '.png', dpi=300, bbox_inches='tight')
plt.show()


print (test_acc)